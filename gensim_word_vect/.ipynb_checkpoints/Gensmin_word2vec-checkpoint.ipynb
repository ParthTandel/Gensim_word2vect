{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gensim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder for your text files goes here\n",
    "# change the path if you want to run on a different corpus or you have files in different location\n",
    "paths = glob.glob('../word2vect_python/MorpedTextedWWO/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "newFullText  = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    with open(path, \"r\") as f:\n",
    "        newFullText += f.read().split(\"\\n\")[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = newFullText.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_word_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    sentences_word_list.append(sentence.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-25 15:01:20,244 : INFO : collecting all words and their counts\n",
      "2018-05-25 15:01:20,248 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-05-25 15:01:20,332 : INFO : PROGRESS: at sentence #10000, processed 429638 words, keeping 28761 word types\n",
      "2018-05-25 15:01:20,380 : INFO : PROGRESS: at sentence #20000, processed 762243 words, keeping 38265 word types\n",
      "2018-05-25 15:01:20,463 : INFO : PROGRESS: at sentence #30000, processed 1335860 words, keeping 48252 word types\n",
      "2018-05-25 15:01:20,507 : INFO : PROGRESS: at sentence #40000, processed 1624935 words, keeping 56938 word types\n",
      "2018-05-25 15:01:20,567 : INFO : PROGRESS: at sentence #50000, processed 1967547 words, keeping 64772 word types\n",
      "2018-05-25 15:01:20,620 : INFO : PROGRESS: at sentence #60000, processed 2283912 words, keeping 69354 word types\n",
      "2018-05-25 15:01:20,662 : INFO : PROGRESS: at sentence #70000, processed 2575999 words, keeping 72909 word types\n",
      "2018-05-25 15:01:20,717 : INFO : PROGRESS: at sentence #80000, processed 2942177 words, keeping 78069 word types\n",
      "2018-05-25 15:01:20,788 : INFO : PROGRESS: at sentence #90000, processed 3365541 words, keeping 82104 word types\n",
      "2018-05-25 15:01:20,834 : INFO : PROGRESS: at sentence #100000, processed 3640837 words, keeping 86672 word types\n",
      "2018-05-25 15:01:20,903 : INFO : PROGRESS: at sentence #110000, processed 4050943 words, keeping 90561 word types\n",
      "2018-05-25 15:01:20,965 : INFO : PROGRESS: at sentence #120000, processed 4427728 words, keeping 95144 word types\n",
      "2018-05-25 15:01:21,019 : INFO : PROGRESS: at sentence #130000, processed 4784875 words, keeping 98254 word types\n",
      "2018-05-25 15:01:21,096 : INFO : PROGRESS: at sentence #140000, processed 5225958 words, keeping 103117 word types\n",
      "2018-05-25 15:01:21,139 : INFO : PROGRESS: at sentence #150000, processed 5496059 words, keeping 106939 word types\n",
      "2018-05-25 15:01:21,194 : INFO : PROGRESS: at sentence #160000, processed 5828073 words, keeping 109575 word types\n",
      "2018-05-25 15:01:21,249 : INFO : PROGRESS: at sentence #170000, processed 6167718 words, keeping 113159 word types\n",
      "2018-05-25 15:01:21,318 : INFO : PROGRESS: at sentence #180000, processed 6555545 words, keeping 116687 word types\n",
      "2018-05-25 15:01:21,374 : INFO : PROGRESS: at sentence #190000, processed 6896025 words, keeping 118764 word types\n",
      "2018-05-25 15:01:21,434 : INFO : PROGRESS: at sentence #200000, processed 7227294 words, keeping 122275 word types\n",
      "2018-05-25 15:01:21,482 : INFO : PROGRESS: at sentence #210000, processed 7518662 words, keeping 125527 word types\n",
      "2018-05-25 15:01:21,560 : INFO : PROGRESS: at sentence #220000, processed 7994035 words, keeping 128168 word types\n",
      "2018-05-25 15:01:21,620 : INFO : PROGRESS: at sentence #230000, processed 8381628 words, keeping 131360 word types\n",
      "2018-05-25 15:01:21,679 : INFO : PROGRESS: at sentence #240000, processed 8748948 words, keeping 134452 word types\n",
      "2018-05-25 15:01:21,735 : INFO : PROGRESS: at sentence #250000, processed 9092434 words, keeping 136991 word types\n",
      "2018-05-25 15:01:21,771 : INFO : PROGRESS: at sentence #260000, processed 9306524 words, keeping 138758 word types\n",
      "2018-05-25 15:01:21,819 : INFO : PROGRESS: at sentence #270000, processed 9532217 words, keeping 139989 word types\n",
      "2018-05-25 15:01:21,899 : INFO : PROGRESS: at sentence #280000, processed 9949986 words, keeping 143565 word types\n",
      "2018-05-25 15:01:21,984 : INFO : PROGRESS: at sentence #290000, processed 10386747 words, keeping 146774 word types\n",
      "2018-05-25 15:01:22,055 : INFO : PROGRESS: at sentence #300000, processed 10733233 words, keeping 148453 word types\n",
      "2018-05-25 15:01:22,137 : INFO : PROGRESS: at sentence #310000, processed 11166896 words, keeping 152373 word types\n",
      "2018-05-25 15:01:22,204 : INFO : PROGRESS: at sentence #320000, processed 11553350 words, keeping 154567 word types\n",
      "2018-05-25 15:01:22,275 : INFO : PROGRESS: at sentence #330000, processed 11985457 words, keeping 155995 word types\n",
      "2018-05-25 15:01:22,356 : INFO : PROGRESS: at sentence #340000, processed 12399113 words, keeping 158039 word types\n",
      "2018-05-25 15:01:22,432 : INFO : PROGRESS: at sentence #350000, processed 12793363 words, keeping 160786 word types\n",
      "2018-05-25 15:01:22,487 : INFO : collected 163159 word types from a corpus of 13074954 raw words and 358545 sentences\n",
      "2018-05-25 15:01:22,488 : INFO : Loading a fresh vocabulary\n",
      "2018-05-25 15:01:22,651 : INFO : min_count=5 retains 51396 unique words (31% of original 163159, drops 111763)\n",
      "2018-05-25 15:01:22,652 : INFO : min_count=5 leaves 12899889 word corpus (98% of original 13074954, drops 175065)\n",
      "2018-05-25 15:01:22,772 : INFO : deleting the raw counts dictionary of 163159 items\n",
      "2018-05-25 15:01:22,779 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2018-05-25 15:01:22,780 : INFO : downsampling leaves estimated 9050223 word corpus (70.2% of prior 12899889)\n",
      "2018-05-25 15:01:22,980 : INFO : estimated required memory for 51396 words and 128 dimensions: 78327504 bytes\n",
      "2018-05-25 15:01:22,980 : INFO : resetting layer weights\n",
      "2018-05-25 15:01:23,455 : INFO : training model with 3 workers on 51396 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=12\n",
      "2018-05-25 15:01:24,461 : INFO : EPOCH 1 - PROGRESS: at 7.26% examples, 799040 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:25,466 : INFO : EPOCH 1 - PROGRESS: at 16.35% examples, 775100 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:26,475 : INFO : EPOCH 1 - PROGRESS: at 26.36% examples, 789793 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:27,480 : INFO : EPOCH 1 - PROGRESS: at 35.73% examples, 814382 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:28,482 : INFO : EPOCH 1 - PROGRESS: at 45.96% examples, 825276 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:29,486 : INFO : EPOCH 1 - PROGRESS: at 55.27% examples, 824078 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:30,489 : INFO : EPOCH 1 - PROGRESS: at 64.98% examples, 834891 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:31,495 : INFO : EPOCH 1 - PROGRESS: at 76.47% examples, 833106 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:32,496 : INFO : EPOCH 1 - PROGRESS: at 85.68% examples, 839508 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:33,497 : INFO : EPOCH 1 - PROGRESS: at 93.44% examples, 841847 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:34,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 15:01:34,198 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 15:01:34,205 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 15:01:34,206 : INFO : EPOCH - 1 : training on 13074954 raw words (9049615 effective words) took 10.7s, 842001 effective words/s\n",
      "2018-05-25 15:01:35,219 : INFO : EPOCH 2 - PROGRESS: at 7.50% examples, 844565 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:36,221 : INFO : EPOCH 2 - PROGRESS: at 18.23% examples, 842968 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:37,225 : INFO : EPOCH 2 - PROGRESS: at 28.19% examples, 850082 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:38,227 : INFO : EPOCH 2 - PROGRESS: at 36.79% examples, 840141 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:39,230 : INFO : EPOCH 2 - PROGRESS: at 46.97% examples, 843744 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:40,233 : INFO : EPOCH 2 - PROGRESS: at 57.52% examples, 847012 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:41,241 : INFO : EPOCH 2 - PROGRESS: at 65.76% examples, 845780 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:42,250 : INFO : EPOCH 2 - PROGRESS: at 77.85% examples, 849783 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:43,254 : INFO : EPOCH 2 - PROGRESS: at 86.50% examples, 853092 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:44,256 : INFO : EPOCH 2 - PROGRESS: at 95.04% examples, 856460 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:44,736 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 15:01:44,742 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 15:01:44,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 15:01:44,748 : INFO : EPOCH - 2 : training on 13074954 raw words (9051049 effective words) took 10.5s, 858927 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-25 15:01:45,756 : INFO : EPOCH 3 - PROGRESS: at 7.40% examples, 829143 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:46,765 : INFO : EPOCH 3 - PROGRESS: at 18.91% examples, 859027 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:47,770 : INFO : EPOCH 3 - PROGRESS: at 28.90% examples, 870178 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:48,773 : INFO : EPOCH 3 - PROGRESS: at 37.82% examples, 872239 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:49,779 : INFO : EPOCH 3 - PROGRESS: at 49.11% examples, 877701 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:50,779 : INFO : EPOCH 3 - PROGRESS: at 59.25% examples, 879259 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:51,780 : INFO : EPOCH 3 - PROGRESS: at 68.54% examples, 882608 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:52,791 : INFO : EPOCH 3 - PROGRESS: at 80.30% examples, 884099 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:53,795 : INFO : EPOCH 3 - PROGRESS: at 89.34% examples, 883800 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:54,807 : INFO : EPOCH 3 - PROGRESS: at 98.02% examples, 884146 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:54,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 15:01:54,976 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 15:01:54,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 15:01:54,979 : INFO : EPOCH - 3 : training on 13074954 raw words (9049202 effective words) took 10.2s, 885182 effective words/s\n",
      "2018-05-25 15:01:55,989 : INFO : EPOCH 4 - PROGRESS: at 7.65% examples, 879971 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:56,995 : INFO : EPOCH 4 - PROGRESS: at 19.34% examples, 878327 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:01:58,012 : INFO : EPOCH 4 - PROGRESS: at 28.97% examples, 877847 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:01:59,018 : INFO : EPOCH 4 - PROGRESS: at 38.31% examples, 881540 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:02:00,021 : INFO : EPOCH 4 - PROGRESS: at 49.66% examples, 887117 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:02:01,032 : INFO : EPOCH 4 - PROGRESS: at 59.80% examples, 888673 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:02,040 : INFO : EPOCH 4 - PROGRESS: at 69.44% examples, 889233 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:02:03,042 : INFO : EPOCH 4 - PROGRESS: at 80.73% examples, 888026 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:04,044 : INFO : EPOCH 4 - PROGRESS: at 89.91% examples, 888390 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:05,046 : INFO : EPOCH 4 - PROGRESS: at 98.76% examples, 888710 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:05,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 15:02:05,153 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 15:02:05,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 15:02:05,158 : INFO : EPOCH - 4 : training on 13074954 raw words (9049929 effective words) took 10.2s, 889381 effective words/s\n",
      "2018-05-25 15:02:06,167 : INFO : EPOCH 5 - PROGRESS: at 7.59% examples, 868885 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:07,168 : INFO : EPOCH 5 - PROGRESS: at 19.49% examples, 892019 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:08,170 : INFO : EPOCH 5 - PROGRESS: at 28.96% examples, 884915 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:09,175 : INFO : EPOCH 5 - PROGRESS: at 38.25% examples, 885258 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:10,185 : INFO : EPOCH 5 - PROGRESS: at 49.62% examples, 888935 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:11,188 : INFO : EPOCH 5 - PROGRESS: at 59.74% examples, 890178 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:02:12,198 : INFO : EPOCH 5 - PROGRESS: at 69.32% examples, 890038 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:02:13,201 : INFO : EPOCH 5 - PROGRESS: at 80.87% examples, 891993 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:02:14,203 : INFO : EPOCH 5 - PROGRESS: at 89.99% examples, 891870 words/s, in_qsize 6, out_qsize 0\n",
      "2018-05-25 15:02:15,213 : INFO : EPOCH 5 - PROGRESS: at 99.03% examples, 891716 words/s, in_qsize 5, out_qsize 0\n",
      "2018-05-25 15:02:15,289 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-05-25 15:02:15,299 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-05-25 15:02:15,306 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-25 15:02:15,306 : INFO : EPOCH - 5 : training on 13074954 raw words (9046911 effective words) took 10.1s, 891998 effective words/s\n",
      "2018-05-25 15:02:15,307 : INFO : training on a 65374770 raw words (45246706 effective words) took 51.9s, 872632 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences_word_list, size=128, window=12, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_words(word, vocab, model, k=10):\n",
    "    sims = []\n",
    "    for i in vocab:\n",
    "        sims.append(model[i])\n",
    "    similarities = cosine_similarity([model[word]], sims)[0]\n",
    "    sort = np.argsort(similarities)[::-1]\n",
    "    probs = []\n",
    "    for x in sort[0:k]:\n",
    "        probs.append((similarities[x], reverse_dictionary[x]))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model.wv.vocab:\n",
    "    vocab.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parth/tf/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/home/parth/tf/lib/python3.5/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.12696497  0.17071949  0.25557676  0.00103621  0.15426381 -0.10246807\n",
      "  0.20792775  0.02740777  0.00697624  0.13673814]\n"
     ]
    }
   ],
   "source": [
    "top_n_words(\"king\", vocab, model, k=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
